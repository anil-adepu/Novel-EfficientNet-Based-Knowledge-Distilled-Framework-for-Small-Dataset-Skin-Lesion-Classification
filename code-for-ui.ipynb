{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U --pre efficientnet >> /dev/null\n!pip install tensorflow-addons","metadata":{"execution":{"iopub.status.busy":"2023-05-04T17:07:54.884364Z","iopub.execute_input":"2023-05-04T17:07:54.885404Z","iopub.status.idle":"2023-05-04T17:08:20.771493Z","shell.execute_reply.started":"2023-05-04T17:07:54.885352Z","shell.execute_reply":"2023-05-04T17:08:20.770082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-05-04T17:08:29.879945Z","iopub.execute_input":"2023-05-04T17:08:29.880455Z","iopub.status.idle":"2023-05-04T17:08:47.890867Z","shell.execute_reply.started":"2023-05-04T17:08:29.88041Z","shell.execute_reply":"2023-05-04T17:08:47.889334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\neb5model_filepath ='/kaggle/input/haminterfacetestdata/E5/HAMe5fold-2.h5'\neb5eb5model_filepath ='/kaggle/input/haminterfacetestdata/e5e5distV2(to temp)/Disfold-2.h5'\neb5eb5bestmodel_filepath ='/kaggle/input/haminterfacetestdata/E5E5_aplha-0-425-Notemp/Dis_v22E5E5NoTemp_0_425_Alpha_fold-2.h5'","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:50:48.649982Z","iopub.execute_input":"2023-05-04T18:50:48.650456Z","iopub.status.idle":"2023-05-04T18:50:48.656865Z","shell.execute_reply.started":"2023-05-04T18:50:48.650422Z","shell.execute_reply":"2023-05-04T18:50:48.655409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Input\nfrom keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nimport matplotlib.pyplot as plt\nfrom keras import backend as K\nimport numpy as np\n#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom PIL import Image, ImageChops\nimport random\n#import gradio as gr\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom functools import partial\nimport sklearn\nfrom tqdm import tqdm_notebook as tqdm\nimport gc\nfrom keras.models import load_model\n#from focal_loss import BinaryFocalLoss\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:50:50.395209Z","iopub.execute_input":"2023-05-04T18:50:50.39566Z","iopub.status.idle":"2023-05-04T18:50:50.407327Z","shell.execute_reply.started":"2023-05-04T18:50:50.395623Z","shell.execute_reply":"2023-05-04T18:50:50.406108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classes = ['Melanocytic nevus', 'Melanoma', 'Benign keratosis', 'Dermatofibroma', 'Squamous cell carcinoma', 'Basal cell carcinoma', 'Vascular lesion', 'Actinic keratosis']\nclasses = ['Melanoma','Melanocytic nevus','Basal cell carcinoma','Actinic keratosis', 'Benign keratosis','Dermatofibroma','Vascular lesion']\n#CLASSES = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:50:56.519428Z","iopub.execute_input":"2023-05-04T18:50:56.519854Z","iopub.status.idle":"2023-05-04T18:50:56.52678Z","shell.execute_reply.started":"2023-05-04T18:50:56.519819Z","shell.execute_reply":"2023-05-04T18:50:56.525493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Add, Dense\nfrom tensorflow.keras.models import Model\nimport tensorflow_addons as tfa\n","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:50:57.598095Z","iopub.execute_input":"2023-05-04T18:50:57.598535Z","iopub.status.idle":"2023-05-04T18:50:57.604455Z","shell.execute_reply.started":"2023-05-04T18:50:57.598498Z","shell.execute_reply":"2023-05-04T18:50:57.603192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\nEFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\ndef get_EFF_NET2(dim=384,output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    \n    inp = tf.keras.layers.Input(shape=(dim,dim,3), name='inp')\n    base = EFNS[2](input_shape=(dim,dim,3),weights='noisy-student',include_top=False)\n    base.trainable = True\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(7,activation='softmax', bias_initializer=output_bias)(x)\n    model = tf.keras.Model(inputs=[inp],outputs=[x])\n    return model\ndef get_EFF_NET5(dim=384,output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    \n    inp = tf.keras.layers.Input(shape=(dim,dim,3), name='inp')\n    base = EFNS[5](input_shape=(dim,dim,3),weights='noisy-student',include_top=False)\n    base.trainable = True\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(7,activation='softmax', bias_initializer=output_bias)(x)\n    model = tf.keras.Model(inputs=[inp],outputs=[x])\n    opti = tfa.optimizers.RectifiedAdam(learning_rate=0.00032, total_steps=10000,\n                               warmup_proportion=0.1, min_lr=1e-7)\n    loss= tf.keras.losses.SparseCategoricalCrossentropy()\n    METRICS = [tf.keras.metrics.SparseCategoricalAccuracy()]\n    model.compile(optimizer=opti, loss=loss, metrics=METRICS)\n    return model\n\n\ndef get_EFF_NET7(dim=384,output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    \n    inp = tf.keras.layers.Input(shape=(dim,dim,3), name='inp')\n    base = EFNS[7](input_shape=(dim,dim,3),weights='noisy-student',include_top=False)\n    base.trainable = True\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(7,activation='softmax', bias_initializer=output_bias)(x)\n    model = tf.keras.Model(inputs=[inp],outputs=[x])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:51:00.957765Z","iopub.execute_input":"2023-05-04T18:51:00.95823Z","iopub.status.idle":"2023-05-04T18:51:00.977328Z","shell.execute_reply.started":"2023-05-04T18:51:00.958192Z","shell.execute_reply":"2023-05-04T18:51:00.976313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# modeleb2 = get_EFF_NET2()\n# modeleb2.load_weights(eb2model_filepath)\n# #modeleb2=tf.keras.models.load_model(eb2model_filepath)\n# modeleb5 = get_EFF_NET5()\n# modeleb5.load_weights(eb5model_filepath)\n# modeleb7 = get_EFF_NET7()\n# modeleb7.load_weights(eb7model_filepath)\n\nmodeleb5 = get_EFF_NET5()\nmodeleb5.load_weights(eb5model_filepath)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:51:04.879435Z","iopub.execute_input":"2023-05-04T18:51:04.879872Z","iopub.status.idle":"2023-05-04T18:51:13.426916Z","shell.execute_reply.started":"2023-05-04T18:51:04.879836Z","shell.execute_reply":"2023-05-04T18:51:13.425698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Distiller(tf.keras.Model):\n    def __init__(self, student, teacher):\n        super(Distiller, self).__init__()\n        self.teacher = teacher\n        self.student = student\n\n    def compile(\n        self,\n        optimizer,\n        metrics,\n        student_loss_fn,\n        distillation_loss_fn,\n        alpha=0.5,\n        temperature=1,\n    ):\n        \"\"\" Configure the distiller.\n        Args:\n            optimizer: Keras optimizer for the student weights\n            metrics: Keras metrics for evaluation\n            student_loss_fn: Loss function of difference between student\n                predictions and ground-truth\n            distillation_loss_fn: Loss function of difference between soft\n                student predictions and soft teacher predictions\n            alpha: weight to distillation_loss_fn and 1-alpha to student_loss_fn\n            temperature: Temperature for softening probability distributions.\n                Larger temperature gives softer distributions.\n        \"\"\"\n        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n        self.student_loss_fn = student_loss_fn\n        self.distillation_loss_fn = distillation_loss_fn\n        self.alpha = alpha\n        self.temperature = temperature\n    def train_step(self, data):\n        # Unpack data\n        x, y_ = data\n        y = y_\n        #y = tf.reshape(y_, (-1,7))\n        # Forward pass of teacher\n        teacher_predictions = self.teacher(x, training=False)\n\n        with tf.GradientTape() as tape:\n            # Forward pass of student\n            student_predictions = self.student(x, training=True)\n\n\n            loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n            per_example_loss = loss_object(y, student_predictions)\n            student_loss = tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZES[fold]*REPLICAS)\n            \n            teacher_logit = (tf.math.log(teacher_predictions) - tf.math.log(1-teacher_predictions))\n            teacher_predictions_soft = tf.math.sigmoid(teacher_logit/self.temperature)\n            student_logit = (tf.math.log(student_predictions) - tf.math.log(1-student_predictions))\n            student_predictions_soft = tf.math.sigmoid(student_logit/self.temperature)\n\n\n            # L_soft\n            per_example_loss_ = self.distillation_loss_fn(\n                teacher_predictions,\n                student_predictions,\n            )\n            distillation_loss = tf.nn.compute_average_loss(per_example_loss_, global_batch_size=BATCH_SIZES[fold]*REPLICAS)\n\n#           Lstudent = αKD · Lsoft + (1 − αKD) · Lhard\n            loss = (self.alpha) * distillation_loss + (1 - self.alpha) * student_loss\n\n\n\n        trainable_vars = self.student.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n\n\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n\n\n        self.compiled_metrics.update_state(y, student_predictions)\n\n        # Return a dict of performance\n        results = {m.name: m.result() for m in self.metrics}\n        results.update(\n            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n        )\n        return results\n    \n    def test_step(self, data):\n        # Unpack the data\n        x, y_ = data\n        y = y_\n        #y = tf.reshape(y_, (-1,7))\n        # Compute predictions\n        y_prediction = self.student(x, training=False)\n\n        # Calculate the loss\n        #student_loss = self.student_loss_fn(y, y_prediction)\n        \n        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n        per_example_loss = loss_object(y, y_prediction)\n        student_loss = tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZES[fold]*REPLICAS)\n\n        # Update the metrics.\n        self.compiled_metrics.update_state(y, y_prediction)\n\n        # Return a dict of performance\n        results = {m.name: m.result() for m in self.metrics}\n        results.update({\"student_loss\": student_loss})\n        return results\n\n    def call(self, data):\n        y_pred = self.student(data) \n        return y_pred\n\n    @tf.function\n    def distributed_train_step(dist_inputs):\n        per_replica_losses = strategy.run(train_step, args=(dist_inputs,))\n        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n                             axis=None)\n\n    @tf.function\n    def distributed_test_step(dist_inputs):\n        return strategy.run(test_step, args=(dist_inputs,))\n    \nopt = tfa.optimizers.RectifiedAdam(lr=0.00032, total_steps=10000,\n                               warmup_proportion=0.1, min_lr=1e-7)\nopti = tfa.optimizers.Lookahead(opt, sync_period=5, slow_step_size=0.8)\nloss= tf.keras.losses.SparseCategoricalCrossentropy()\nMETRICS = [tf.keras.metrics.SparseCategoricalAccuracy()]\nteacher = get_EFF_NET5()#dim=IMG_SIZES[fold],ef=5, output_bias = None)\nstudent = get_EFF_NET5()#dim=IMG_SIZES[fold],ef=0, output_bias = None)\ndistiller = Distiller(student=student, teacher=teacher)\nstudent_scratch = tf.keras.models.clone_model(student)\n# distillation_loss_fn22 = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.NONE)\n\ndistiller.compile(\n            optimizer=opti,\n            metrics=METRICS,\n            student_loss_fn=loss,\n            distillation_loss_fn=tf.keras.losses.KLDivergence(\n                        reduction=tf.keras.losses.Reduction.NONE),\n            alpha=0.40,\n            temperature=1,)\ndistiller.built = True","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:51:21.764603Z","iopub.execute_input":"2023-05-04T18:51:21.765067Z","iopub.status.idle":"2023-05-04T18:51:43.65352Z","shell.execute_reply.started":"2023-05-04T18:51:21.765032Z","shell.execute_reply":"2023-05-04T18:51:43.652241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modeleb5eb5 = Distiller(student=student, teacher=teacher)\nstudent_scratch = tf.keras.models.clone_model(student)\n# distillation_loss_fn22 = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.NONE)\n\nmodeleb5eb5.compile(\n            optimizer=opti,\n            metrics=METRICS,\n            student_loss_fn=loss,\n            distillation_loss_fn=tf.keras.losses.KLDivergence(\n                        reduction=tf.keras.losses.Reduction.NONE),\n            alpha=0.40,\n            temperature=1,)\nmodeleb5eb5.built = True\nmodeleb5eb5.load_weights(eb5eb5model_filepath)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:52:09.844297Z","iopub.execute_input":"2023-05-04T18:52:09.844744Z","iopub.status.idle":"2023-05-04T18:52:20.523759Z","shell.execute_reply.started":"2023-05-04T18:52:09.844712Z","shell.execute_reply":"2023-05-04T18:52:20.522648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modeleb5eb5best = Distiller(student=student, teacher=teacher)\nstudent_scratch = tf.keras.models.clone_model(student)\n# distillation_loss_fn22 = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.NONE)\n\nmodeleb5eb5best.compile(\n            optimizer=opti,\n            metrics=METRICS,\n            student_loss_fn=loss,\n            distillation_loss_fn=tf.keras.losses.KLDivergence(\n                        reduction=tf.keras.losses.Reduction.NONE),\n            alpha=0.40,\n            temperature=1,)\nmodeleb5eb5best.built = True\nmodeleb5eb5best.load_weights(eb5eb5bestmodel_filepath)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:52:24.182697Z","iopub.execute_input":"2023-05-04T18:52:24.18319Z","iopub.status.idle":"2023-05-04T18:52:35.141848Z","shell.execute_reply.started":"2023-05-04T18:52:24.183151Z","shell.execute_reply":"2023-05-04T18:52:35.140681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gradio as gr","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:52:48.091732Z","iopub.execute_input":"2023-05-04T18:52:48.092196Z","iopub.status.idle":"2023-05-04T18:52:50.536556Z","shell.execute_reply.started":"2023-05-04T18:52:48.092161Z","shell.execute_reply":"2023-05-04T18:52:50.535465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_classifier(inp,val):\n    remarks=\"\"\n    output = \"\"\n    #print(type(inp))\n    #print(val)\n    #print(\"H1\")\n    if inp is None:\n        remarks=\"Please Select a valid input image\"\n    else:\n        img = cv2.cvtColor(np.array(inp), cv2.COLOR_RGB2BGR)\n        img = cv2.resize(img, (384, 384))\n        img = img/255\n        img = np.expand_dims(img, axis = 0)\n        \n        if val == \"EfficientnetB5Only\":\n            print(\"here\")\n            pre=modeleb5.predict(img)[0]\n            print(pre)\n            max_valuei = np.argmax(pre)\n            output = classes[max_valuei]\n            remarks = ' , '.join([str(elem) for elem in pre ])\n            remarks = \"Model Output : \" +remarks\n        elif val == \"EfficientnetB5StudentB5Teacher\":\n            pre=modeleb5eb5.predict(img)[0]\n            max_valuei = np.argmax(pre)\n            output = classes[max_valuei]\n            remarks = ' , '.join([str(elem) for elem in pre ])\n            remarks = \"Model Output : \" +remarks\n        else:\n            pre=modeleb5eb5best.predict(img)[0]\n            max_valuei = np.argmax(pre)\n            output = classes[max_valuei]\n            remarks = ' , '.join([str(elem) for elem in pre ])\n            remarks = \"Model Output : \" +remarks\n#         else:\n#             pre=modelcus.predict(img)[0]\n#             max_valuei = np.argmax(pre)\n#             output = classes[max_valuei]\n#             remarks = ' , '.join([str(elem) for elem in pre ])\n#             remarks = \"Model Output : \" +remarks\n            #stats,remarks= use_model1(inp)\n#         else:\n#             print(\"HII\")\n            #stats,remarks= use_model2(inp)\n            #remarks=\" Pred \"\n            #stats={'Melanoma':0.0,'Non-Melanoma':0.0}\n        #rem#arks=str(type(inp))\n        #print(val)\n    #     #call model\n    #     pass\n    #     stats['melanoma']=0.9\n    #     stats['Non-melanoma']=0.1\n        \n    #print(\"going to return\")\n    #print(stats)\n    #print(remarks)   \n    return remarks,output","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:53:07.373537Z","iopub.execute_input":"2023-05-04T18:53:07.373946Z","iopub.status.idle":"2023-05-04T18:53:07.387172Z","shell.execute_reply.started":"2023-05-04T18:53:07.373914Z","shell.execute_reply":"2023-05-04T18:53:07.385907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"demo = gr.Interface(fn=image_classifier, \n                    inputs=[gr.Image(type=\"pil\"),gr.Radio([\"EfficientnetB5Only\", \"EfficientnetB5StudentB5Teacher\", \"EfficientnetB5StudentB5TeacherRefined\"],value=\"EfficientnetB5StudentB5TeacherRefined\"),], \n                    outputs=[gr.Textbox(placeholder=\"Remarks\",label=\"Output Remarks\"),gr.Label(value=\"Output\",label=\"Classification Output\")],\n                    title=\"MultiClass Skin Lesion Classification\",\n                    description=\"Please upload a valid skin lesion image,select the required model and press submit\",\n                    article=\"By Kiran Thomas Cherian CED18I028\",\n                    allow_flagging=\"never\",\n                    css=\"footer {visibility: hidden}\"\n                    )\n                    \ndemo.launch(share=True,debug=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T18:53:21.196355Z","iopub.execute_input":"2023-05-04T18:53:21.197461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def our_cnn(dim=384, num_classes=8):\n#     input_shape = (dim, dim, 3)\n#     num_classes = 8\n\n#     model = tf.keras.Sequential([\n#         layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n#         layers.BatchNormalization(),\n#         layers.Conv2D(32, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.MaxPooling2D((2, 2)),\n#         layers.Dropout(0.25),\n\n#         layers.Conv2D(64, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.Conv2D(64, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.MaxPooling2D((2, 2)),\n#         layers.Dropout(0.25),\n\n#         layers.Conv2D(128, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.Conv2D(128, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.MaxPooling2D((2, 2)),\n#         layers.Dropout(0.25),\n\n#         layers.Conv2D(256, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.Conv2D(256, (3, 3), activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.MaxPooling2D((2, 2)),\n#         layers.Dropout(0.25),\n\n#         layers.Flatten(),\n#         layers.Dense(512, activation='relu'),\n#         layers.BatchNormalization(),\n#         layers.Dropout(0.5),\n#         layers.Dense(num_classes, activation='softmax')\n#     ])\n    return model","metadata":{},"execution_count":null,"outputs":[]}]}