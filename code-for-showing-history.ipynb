{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc # garbage collection\nfrom kaggle_datasets import KaggleDatasets\nimport re, math\nimport tensorflow.keras.backend as K\nfrom tensorflow.python.keras.utils import losses_utils\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import class_weight\nimport matplotlib.pyplot as plt\nimport pickle\nimport random as r\nimport cv2, os\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-07T13:41:10.622639Z","iopub.execute_input":"2023-05-07T13:41:10.623158Z","iopub.status.idle":"2023-05-07T13:41:21.362236Z","shell.execute_reply.started":"2023-05-07T13:41:10.623107Z","shell.execute_reply":"2023-05-07T13:41:21.36101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = \"TPU\" # or \"GPU\"\nSEED = 42 # USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\nFOLDS = 5 # NUMBER OF FOLDS. USE 3, 5, OR 15 \nIMG_SIZES = [384] * FOLDS\nBATCH_SIZES = [32] * FOLDS\nEPOCHS = [40] * FOLDS\nEFF_NETS = [5] * FOLDS\nWGTS = [1 / FOLDS] * FOLDS # WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\nTTA = 15 # TEST TIME AUGMENTATION FACTOR\nNUMOFCLASSES = 7\nCLASSWEIGHTS = {0:1.28545758 , 1: 0.21338021,2:2.78349083 ,3:4.37527304 ,4:1.30183284,5:12.44099379,6:10.07545272} \n\nCLASSES = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']\nVERBOSE = 1\nDISPLAY_PLOT = True\n\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\nclsz=7","metadata":{"execution":{"iopub.status.busy":"2023-05-07T13:41:21.364495Z","iopub.execute_input":"2023-05-07T13:41:21.365228Z","iopub.status.idle":"2023-05-07T13:41:21.374993Z","shell.execute_reply.started":"2023-05-07T13:41:21.365189Z","shell.execute_reply":"2023-05-07T13:41:21.373567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npredwithtta=pd.read_csv('/kaggle/input/hame5output/HAMDiswith_TTA_submission.csv')\npredwithouttta=pd.read_csv('/kaggle/input/hame5output/HAMDiswithout_TTA_submission.csv')\n\nfor fold,(idxT,idxV) in enumerate(skf.split(np.arange(FOLDS))):  \n    with open(\"/kaggle/input/hame5output/Dis_history_fold-%i.p\"%(fold+1), 'rb') as pickle_file:\n        history = pickle.load(pickle_file)\n#         print(history)\n#         DISPLAY_PLOT=False\n#         break\n    #hist = pickle.load(\")\n    #pickle.dump(hist, open(\"history_fold-%i.p\"%(fold+1), \"wb\"))\n    # PLOT TRAINING\n        if DISPLAY_PLOT:\n            plt.figure(figsize=(15,5))\n            plt.plot(np.arange(len(history['sparse_categorical_accuracy'])),history['sparse_categorical_accuracy'],'-o',label='Train sparse_categorical_accuracy',color='#ff7f0e')\n            plt.plot(np.arange(len(history['sparse_categorical_accuracy'])),history['val_sparse_categorical_accuracy'],'-o',label='Val val_sparse_categorical_accuracy',color='#1f77b4')\n            x = np.argmax( history['val_sparse_categorical_accuracy'] ); y = np.max( history['val_sparse_categorical_accuracy'] )\n            xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n            plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max sparse_categorical_accuracy\\n%.4f'%y,size=14)\n            plt.ylabel('acc',size=14); plt.xlabel('Epoch',size=14)\n            plt.legend(loc=2)\n            plt2 = plt.gca().twinx()\n            plt2.plot(np.arange(len(history['student_loss'])),history['student_loss'],'-o',label='student_loss',color='#FF0000')\n            plt2.plot(np.arange(len(history['distillation_loss'])),history['distillation_loss'],'-o',label='distillation_loss',color='#2ca02c')\n            plt2.plot(np.arange(len(history['distillation_loss'])),history['val_student_loss'],'-o',label='val_student_loss',color='#1f77b4')\n            x = np.argmin( history['val_student_loss'] ); y = np.min( history['val_student_loss'] )\n            ydist = plt.ylim()[1] - plt.ylim()[0]\n            #plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss%.4f'%y,size=14)\n            plt.ylabel('Loss',size=14)\n            plt.title('FOLD %i '% (fold+1),size=18)\n            plt.legend(loc=3)\n            plt.show()\nclsz = 7            \nactual=pd.read_csv('/kaggle/input/isic2018task3groundtruth/ISIC2018_Task3_Test_GroundTruth.csv')\nactual = actual.drop(['lesion_id','dx_type','age','localization','dataset','sex'], axis=1)\ndummies = pd.get_dummies(actual['dx'])\nactual = pd.concat([actual, dummies], axis=1)\nactual = actual.drop(['dx'],axis=1)\nactual=actual.reindex(columns=['image_id','mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc'])\nactual['mel'] = actual['mel'].astype(float)\nactual['nv'] = actual['nv'].astype(float)\nactual['bcc'] = actual['bcc'].astype(float)\nactual['akiec'] = actual['akiec'].astype(float)\nactual['bkl'] = actual['bkl'].astype(float)\nactual['df'] = actual['df'].astype(float)\nactual['vasc'] = actual['vasc'].astype(float)\nprint(actual.head())\n\n\npredwithtta = predwithtta.rename(columns={'image_name' :'image_id','targetA':'mel','targetB':'nv','targetC':'bcc','targetD':'akiec','targetE':'bkl','targetF':'df','targetG':'vasc'})\ndef set_max_to_one(row):\n    #print(type(row))\n    max_valuei = row.idxmax()\n    row[:] = 0.0\n    row[max_valuei] = 1.0\n    return row\n\n# Apply the function to each row of the DataFrame\npredwithtta[['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']] = predwithtta[['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']].apply(set_max_to_one, axis=1)\n\n# Display the modified DataFrame\nprint(predwithtta.head())\n\n\n\n# Load ground truth and predicted dataframes\ndfA = actual\ndfB = predwithtta\ndfB.columns = [dfB.columns[0]] + [col + \"_y\" for col in dfB.columns[1:]]\n\ndfC = pd.merge(dfA, dfB, on='image_id')\nprint(dfC.head())\n\n# Define the labels for your classification problem\nlabels = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']\n\n# Create a list to store the accuracy for each label\nlabel_acc = []\nprint(\"WIth TTA\")\n\n# Loop through the labels and calculate accuracy, precision, and recall for each label\nfor label in labels:\n    # Calculate accuracy for the label\n    accuracy = (dfC[label] == dfC[label+'_y']).mean()\n    label_acc.append(accuracy)\n    \n    # Calculate precision, recall, and F1-score for the label using classification_report\n    report = classification_report(dfC[label], dfC[label+'_y'], output_dict=True)\n\n    \n    # Print the metrics for the label\n    print('Label:', label)\n    print('stats',report['1.0'])\n    print('---')\n\n\noverall_acc=sum(label_acc)/clsz\nprint('overall_acc:', overall_acc)\ndfC.to_csv('HAMdistE5E5TTAandgroundtruth_alpha-0-35-Notemp.csv', index=False)\n\n\npredwithouttta = predwithouttta.rename(columns={'image_name' :'image_id','targetA':'mel','targetB':'nv','targetC':'bcc','targetD':'akiec','targetE':'bkl','targetF':'df','targetG':'vasc'})\ndef set_max_to_one(row):\n    #print(type(row))\n    max_valuei = row.idxmax()\n    #print(row[:])\n    row[:] = 0.0\n    row[max_valuei] = 1.0\n    return row\n\n# Apply the function to each row of the DataFrame\npredwithouttta[['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']] = predwithouttta[['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']].apply(set_max_to_one, axis=1)\n\n# Display the modified DataFrame\nprint(predwithouttta.head())\n\n# Load ground truth and predicted dataframes\ndfA = actual\ndfB = predwithouttta\ndfB.columns = [dfB.columns[0]] + [col + \"_y\" for col in dfB.columns[1:]]\n\ndfC = pd.merge(dfA, dfB, on='image_id')\nprint(dfC.head())\n\n\n# Define the labels for your classification problem\nlabels = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']\n\n# Create a list to store the accuracy for each label\nlabel_acc = []\nprint(\"WIthout TTA\")\n# Loop through the labels and calculate accuracy, precision, and recall for each label\nfor label in labels:\n    # Calculate accuracy for the label\n    accuracy = (dfC[label] == dfC[label+'_y']).mean()\n    label_acc.append(accuracy)\n    \n    # Calculate precision, recall, and F1-score for the label using classification_report\n    report = classification_report(dfC[label], dfC[label+'_y'], output_dict=True)\n    #print(report)\n    #crt = report['1.0']['f1-score'] > report['macro avg']['f1-score'] ? 'macro avg' : '1.0'\n    crt = '1.0'\n    #precision = report[str(label)]['precision']\n    #recall = report[str(label)]['recall']\n    #f1_score = report[str(label)]['f1-score']\n    \n    # Print the metrics for the label\n    print('Label:', label)\n    print('Stats:',report[crt])\n    print('---')\n\n\noverall_acc=sum(label_acc)/clsz\nprint('overall_acc:', overall_acc)\ndfC.to_csv('HAMdistE5E5withoutTTAandgroundtruth_alpha-0-35-Notemp.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T13:46:06.357044Z","iopub.execute_input":"2023-05-07T13:46:06.357526Z","iopub.status.idle":"2023-05-07T13:46:09.3655Z","shell.execute_reply.started":"2023-05-07T13:46:06.357481Z","shell.execute_reply":"2023-05-07T13:46:09.364535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}